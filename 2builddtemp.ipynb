{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import folktables\n",
    "import numpy as np\n",
    "\n",
    "from bestLS_hindsight import *\n",
    "from OnlineRidgeRiver import *\n",
    "from lean_adahedge import *\n",
    "import matplotlib.pyplot as plt\n",
    "from bestLS_hindsight_together import *\n",
    "from oridge_alwaysactive_implementable import *\n",
    "\n",
    "\n",
    "from folktables.load_acs import state_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, TargetEncoder, StandardScaler, OneHotEncoder\n",
    "def numeric_scaler(df, cols):\n",
    "    '''\n",
    "    df: pandas dataframe\n",
    "    numeric_cols: (array of strings) column names for numeric variables\n",
    "\n",
    "    no return: does inplace operation\n",
    "    '''\n",
    "    df_new = df.copy()\n",
    "    mmscaler = MinMaxScaler()\n",
    "    df_new[cols] = mmscaler.fit_transform(df_new[cols])\n",
    "    return df_new\n",
    "\n",
    "def ordinal_encoder(df, cols): # similar to label encoder which only works for targets?\n",
    "    '''\n",
    "    Encode categorical into 0 ... n-1\n",
    "    '''\n",
    "    df_new = df.copy()\n",
    "    ordinal_enc = OrdinalEncoder()\n",
    "    df_new[cols] = ordinal_enc.fit_transform(df_new[cols])\n",
    "    return df_new\n",
    "\n",
    "def oh_sklearn(df, cols):\n",
    "    pass\n",
    "    # Issues with this operation as it doesnt preseve number of columns etc, the dummies method below works\n",
    "    # df_new = df.copy()\n",
    "    # oh_enc = OneHotEncoder()\n",
    "    # df_new[cols] = oh_enc.fit_transform(df_new[cols])\n",
    "    # return df_new\n",
    "\n",
    "def one_hot(df, cols): # idk if sklearns one-hot encoder is similar\n",
    "    \"\"\"\n",
    "    df: pandas DataFrame\n",
    "    param: cols a list of columns to encode \n",
    "    return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df\n",
    "\n",
    "def target_encoder(df, x_cols, y_col):\n",
    "    df_new = df.copy()\n",
    "    enc_auto = TargetEncoder(smooth=\"auto\", target_type=\"continuous\")\n",
    "    df_new[x_cols] = enc_auto.fit_transform(df_new[x_cols], df[y_col])\n",
    "    return df_new\n",
    "\n",
    "def target_encoder2(df, x_cols, y_col):\n",
    "    df_new = df.copy()\n",
    "    enc_auto = TargetEncoder(smooth=\"auto\", target_type=\"continuous\")\n",
    "    df_new[x_cols] = enc_auto.fit_transform(df_new[x_cols], df[y_col])\n",
    "    return df_new, enc_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ORidgevsAnh_together(cumreg_groupwise_oridge, Anh):\n",
    "  Anhbetter_count = 0\n",
    "  N = len(Anh.cuml_regret_curve)\n",
    "  for gnum in range(N):  \n",
    "    oridge_regret_g = cumreg_groupwise_oridge[gnum]\n",
    "    Tg = len(oridge_regret_g) # number of rounds this group is active\n",
    "    Anh_end = Anh.cuml_regret_curve[gnum][-1] # last time steps cumulative regret\n",
    "    oridge_end = oridge_regret_g[-1]\n",
    "    if Anh_end <= oridge_end:\n",
    "      Anhst = \"Yes\"\n",
    "      Anhbetter_count += 1\n",
    "    else:\n",
    "      Anhst = \"No\"\n",
    "    print(f'''Group number {gnum}, Tg is {Tg} \\n\n",
    "    oridge end regret {oridge_end:.2f}, Anh end regret {Anh_end:.2f}, \\n\n",
    "    Anh better {Anhst} ''')\n",
    "    time_steps = np.arange(1, Tg+1)\n",
    "    plt.plot(time_steps, cumreg_groupwise_oridge[gnum],'-b', label=\"Online Ridge (OR)\")\n",
    "    plt.plot(time_steps, Anh.cuml_regret_curve[gnum], '-r', label=\"Anh with OR meta experts\")\n",
    "    plt.xlabel(\"Time slots\")\n",
    "    plt.ylabel(\"Regret\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.show()\n",
    "  print(f'Anh better for {Anhbetter_count} out of {N} groups') # caught a bug here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OCCP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>ST</th>\n",
       "      <th>JWTRNS</th>\n",
       "      <th>DRAT</th>\n",
       "      <th>COW</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RELSHIPP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>ENG</th>\n",
       "      <th>MAR</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.174295</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.305521</td>\n",
       "      <td>0.525227</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.634268</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.024891</td>\n",
       "      <td>0.440289</td>\n",
       "      <td>0.998451</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.731267</td>\n",
       "      <td>0.039472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019586</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.303514</td>\n",
       "      <td>0.526608</td>\n",
       "      <td>0.440986</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.566230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023964</td>\n",
       "      <td>0.295825</td>\n",
       "      <td>0.998377</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.189201</td>\n",
       "      <td>0.030967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.198418</td>\n",
       "      <td>0.173469</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.305698</td>\n",
       "      <td>0.531881</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.633992</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.026136</td>\n",
       "      <td>0.364825</td>\n",
       "      <td>0.998644</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.730600</td>\n",
       "      <td>0.030467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.143561</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.215190</td>\n",
       "      <td>0.302304</td>\n",
       "      <td>0.531881</td>\n",
       "      <td>0.410761</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.633992</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.026136</td>\n",
       "      <td>0.357630</td>\n",
       "      <td>0.998644</td>\n",
       "      <td>0.691216</td>\n",
       "      <td>0.730600</td>\n",
       "      <td>0.053479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169829</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.305521</td>\n",
       "      <td>0.525227</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.566516</td>\n",
       "      <td>0.995435</td>\n",
       "      <td>0.024891</td>\n",
       "      <td>0.512168</td>\n",
       "      <td>0.998451</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.731267</td>\n",
       "      <td>0.009455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630162</th>\n",
       "      <td>0.584837</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.291139</td>\n",
       "      <td>0.630562</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.440826</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.567354</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.097861</td>\n",
       "      <td>0.638492</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.314840</td>\n",
       "      <td>0.399670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630163</th>\n",
       "      <td>0.437459</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.806307</td>\n",
       "      <td>0.007309</td>\n",
       "      <td>0.440986</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.998820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.097829</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.314533</td>\n",
       "      <td>0.299615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630164</th>\n",
       "      <td>0.232059</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.367089</td>\n",
       "      <td>0.630562</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.440826</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.679348</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.964693</td>\n",
       "      <td>0.097861</td>\n",
       "      <td>0.998644</td>\n",
       "      <td>0.998923</td>\n",
       "      <td>0.314840</td>\n",
       "      <td>0.092501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630165</th>\n",
       "      <td>0.299907</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.630301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857815</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.360696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276848</td>\n",
       "      <td>0.098585</td>\n",
       "      <td>0.641927</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.315268</td>\n",
       "      <td>0.060483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630166</th>\n",
       "      <td>0.177247</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.631386</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.441118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.635949</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.965969</td>\n",
       "      <td>0.101999</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.188575</td>\n",
       "      <td>0.138026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1569188 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             OCCP      WKHP      AGEP      SCHL        ST    JWTRNS      DRAT  \\\n",
       "0        0.174295  0.295918  0.025316  0.305521  0.525227  0.001086  0.000090   \n",
       "1        0.019586  0.397959  0.037975  0.303514  0.526608  0.440986  0.000244   \n",
       "2        0.198418  0.173469  0.025316  0.305698  0.531881  0.000343  0.000416   \n",
       "3        0.143561  0.051020  0.215190  0.302304  0.531881  0.410761  0.000416   \n",
       "4        0.169829  0.091837  0.025316  0.305521  0.525227  0.001086  0.000090   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1630162  0.584837  0.397959  0.291139  0.630562  0.002089  0.440826  0.000416   \n",
       "1630163  0.437459  0.397959  0.379747  0.806307  0.007309  0.440986  0.000861   \n",
       "1630164  0.232059  0.397959  0.367089  0.630562  0.002089  0.440826  0.000416   \n",
       "1630165  0.299907  0.295918  0.063291  0.630301  0.000000  0.857815  0.000244   \n",
       "1630166  0.177247  0.397959  0.493671  0.631386  0.003564  0.441118  0.000000   \n",
       "\n",
       "              COW       SEX  RELSHIPP      POBP       ENG       MAR     RAC1P  \\\n",
       "0        0.634268  0.003645  0.024891  0.440289  0.998451  0.001210  0.731267   \n",
       "1        0.566230  1.000000  0.023964  0.295825  0.998377  0.001598  0.189201   \n",
       "2        0.633992  0.003765  0.026136  0.364825  0.998644  0.001433  0.730600   \n",
       "3        0.633992  0.003765  0.026136  0.357630  0.998644  0.691216  0.730600   \n",
       "4        0.566516  0.995435  0.024891  0.512168  0.998451  0.001210  0.731267   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1630162  0.567354  0.003765  0.999952  0.097861  0.638492  0.001433  0.314840   \n",
       "1630163  0.637931  0.998820  1.000000  0.097829  0.254902  1.000000  0.314533   \n",
       "1630164  0.679348  0.003765  0.964693  0.097861  0.998644  0.998923  0.314840   \n",
       "1630165  0.360696  1.000000  0.276848  0.098585  0.641927  0.001598  0.315268   \n",
       "1630166  0.635949  0.000816  0.965969  0.101999  0.004548  0.999977  0.188575   \n",
       "\n",
       "            PINCP  \n",
       "0        0.039472  \n",
       "1        0.030967  \n",
       "2        0.030467  \n",
       "3        0.053479  \n",
       "4        0.009455  \n",
       "...           ...  \n",
       "1630162  0.399670  \n",
       "1630163  0.299615  \n",
       "1630164  0.092501  \n",
       "1630165  0.060483  \n",
       "1630166  0.138026  \n",
       "\n",
       "[1569188 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_te_scaled = pd.read_pickle(\"./target_encoded/dataframes/data_all_targetencoded_15cols\")\n",
    "df_te_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "bls_undrop = joblib.load('./target_encoded/models/bestsqloss/bls_undropped_15cols.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bls_undrop.make_all_numpyarr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bls_undrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "len(bls_undrop.loss_experts_arr)\n",
    "print(bls_undrop.best_sqloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 15 1569188\n",
      "(1569188, 14) (1569188, 1)\n"
     ]
    }
   ],
   "source": [
    "A_t = np.load('./target_encoded/nparrays/A_t12groups.npy')\n",
    "\n",
    "N = A_t.shape[1] # 12 groups 11 + 1 always active\n",
    "d = df_te_scaled.shape[1] # d uses all 15 columns\n",
    "T = df_te_scaled.shape[0] # ~1.5 million points\n",
    "print(N, d, T) \n",
    "\n",
    "X_dat_te_scaled = df_te_scaled.drop('PINCP', axis=1) #dropping the income column\n",
    "y_dat_te_scaled = pd.DataFrame(df_te_scaled['PINCP']) # picking up only the income column for the target\n",
    "\n",
    "print(X_dat_te_scaled.shape, y_dat_te_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_groups = ['SEX', 'RAC1P']\n",
    "X_dat_te_drop =  X_dat_te_scaled.drop(sensitive_groups, axis=1)\n",
    "y_dat_te_drop = y_dat_te_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bls_undropped = joblib.load('./target_encoded/models/bestsqloss/bls_undropped_15cols.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bls_undropped.best_sqloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./target_encoded/models/Anh/Anh_undropped_15cols.pkl', 'rb') as f:\n",
    "    Anh_undropped = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1569188/1569188 [03:21<00:00, 7794.34it/s]\n"
     ]
    }
   ],
   "source": [
    "or_implementable_undropped = OnlineRidgeImplementable_alwaysactive(X_dat_te_scaled, y_dat_te_scaled) # undropped columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./target_encoded/models/oridge_implementable/oridge_undropped15col.pkl', 'wb') as f:\n",
    "    pickle.dump(or_implementable_undropped, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1569188/1569188 [03:12<00:00, 8154.10it/s]\n"
     ]
    }
   ],
   "source": [
    "or_implementable_dropped = OnlineRidgeImplementable_alwaysactive(X_dat_te_drop, y_dat_te_drop) # undropped columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./target_encoded/models/oridge_implementable/oridge_dropped15col.pkl', 'wb') as f:\n",
    "    pickle.dump(or_implementable_dropped, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multigroup",
   "language": "python",
   "name": "multigroup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
